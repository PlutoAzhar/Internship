{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cbb50f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cd62521",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience_Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Gurgaon/ Gurugram, Haryana, Bangalore/ Bengalu...</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Everest Vacuum</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Synchron Infotech</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst I</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Cerner</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Yulu Bikes</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Persolkelly India</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Shell</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Paychex It Solutions</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/ Bengaluru, Karnataka(Hebbal Kempapura)</td>\n",
       "      <td>Futurlytic</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>MSys Technologies</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Job_Title                                       Job_location  \\\n",
       "0    Data Analyst  Gurgaon/ Gurugram, Haryana, Bangalore/ Bengalu...   \n",
       "1    Data Analyst                                Bangalore/Bengaluru   \n",
       "2    Data Analyst  Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru   \n",
       "3  Data Analyst I                                Bangalore/Bengaluru   \n",
       "4    Data Analyst                                Bangalore/Bengaluru   \n",
       "5    Data Analyst                                Bangalore/Bengaluru   \n",
       "6    Data Analyst                       Chennai, Bangalore/Bengaluru   \n",
       "7    Data Analyst                                Bangalore/Bengaluru   \n",
       "8    Data Analyst  Bangalore/ Bengaluru, Karnataka(Hebbal Kempapura)   \n",
       "9    Data Analyst                                Bangalore/Bengaluru   \n",
       "\n",
       "           Company_Name Experience_Required  \n",
       "0             Delhivery             1-3 Yrs  \n",
       "1        Everest Vacuum             2-5 Yrs  \n",
       "2     Synchron Infotech             5-8 Yrs  \n",
       "3                Cerner            5-10 Yrs  \n",
       "4            Yulu Bikes             4-6 Yrs  \n",
       "5     Persolkelly India             0-2 Yrs  \n",
       "6                 Shell             1-2 Yrs  \n",
       "7  Paychex It Solutions             3-8 Yrs  \n",
       "8            Futurlytic             1-2 Yrs  \n",
       "9     MSys Technologies             2-3 Yrs  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 1\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,'suggestor-input') #Input Data Analyst\n",
    "designation.send_keys('Data Analyst')\n",
    "\n",
    "location=driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input') #Input Bangalore\n",
    "location.send_keys('Banglore')\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,'qsbSubmit') #Click on search\n",
    "search.click()\n",
    "time.sleep(6)\n",
    "\n",
    "#scraping Job title from the given page\n",
    "title=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in a[0:10]:\n",
    "    b=i.text\n",
    "    title.append(b)\n",
    "    \n",
    "    \n",
    "#scraping Job location from the given page\n",
    "location=[]\n",
    "a=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in a[0:10]:\n",
    "    b=i.text\n",
    "    location.append(b) \n",
    "    \n",
    "    \n",
    "#scraping Company name from the given page\n",
    "name=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in a[0:10]:\n",
    "    b=i.text\n",
    "    name.append(b)\n",
    "    \n",
    "\n",
    "#scraping Experience required from the given page\n",
    "exp=[]\n",
    "a=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in a[0:10]:\n",
    "    b=i.text\n",
    "    exp.append(b)\n",
    "\n",
    "\n",
    "print(len(title),len(location),len(name),len(exp))\n",
    "c=pd.DataFrame({'Job_Title':title,'Job_location':location,'Company_Name':name,'Experience_Required':exp})\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc372a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr . Data Scientist / Manager</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Novitas Infotech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Novitas Infotech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN - Applied Intelligence - Finance - Data Sc...</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Gurgaon...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Siemens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Essenware Private Limted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Cargill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>STAFF DATA SCIENTIST</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                   Analystics & Modeling Specialist   \n",
       "2                      Sr . Data Scientist / Manager   \n",
       "3                                     Data Scientist   \n",
       "4  ACN - Applied Intelligence - Finance - Data Sc...   \n",
       "5                              Senior Data Scientist   \n",
       "6                                Lead Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8                              Senior Data Scientist   \n",
       "9                               STAFF DATA SCIENTIST   \n",
       "\n",
       "                                        Job_location              Company_Name  \n",
       "0  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...                 Accenture  \n",
       "1  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...                 Accenture  \n",
       "2       Noida, Gurgaon/Gurugram, Bangalore/Bengaluru          Novitas Infotech  \n",
       "3       Noida, Gurgaon/Gurugram, Bangalore/Bengaluru          Novitas Infotech  \n",
       "4  Hyderabad/Secunderabad, Pune, Chennai, Gurgaon...                 Accenture  \n",
       "5                        Mumbai, Bangalore/Bengaluru         Fractal Analytics  \n",
       "6                                Bangalore/Bengaluru                   Siemens  \n",
       "7                                Bangalore/Bengaluru  Essenware Private Limted  \n",
       "8                                Bangalore/Bengaluru                   Cargill  \n",
       "9                                Bangalore/Bengaluru                   Walmart  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 2\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,'suggestor-input') #Input Data Analyst\n",
    "designation.send_keys('Data Scientist')\n",
    "\n",
    "location=driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input') #Input Bangalore\n",
    "location.send_keys('Banglore')\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,'qsbSubmit') #Click on search\n",
    "search.click()\n",
    "time.sleep(6)\n",
    "\n",
    "#scraping Job title from the given page\n",
    "title=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in a[0:10]:\n",
    "    b=i.text\n",
    "    title.append(b)\n",
    "    \n",
    "\n",
    "#scraping Job location from the given page\n",
    "location=[]\n",
    "a=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in a[0:10]:\n",
    "    b=i.text\n",
    "    location.append(b) \n",
    "    \n",
    "    \n",
    "#scraping Company name from the given page\n",
    "name=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in a[0:10]:\n",
    "    b=i.text\n",
    "    name.append(b)\n",
    "    \n",
    "print(len(title),len(location),len(name),len(exp))\n",
    "c=pd.DataFrame({'Job_Title':title,'Job_location':location,'Company_Name':name})\n",
    "c    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6531107f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience_Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Blackbuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist/ Senior Data Scientist/ Manager...</td>\n",
       "      <td>Noida, Kolkata, Mumbai, Chandigarh, Hyderabad/...</td>\n",
       "      <td>Dreambig It Solutions India</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Times Internet</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python and ML Trainer</td>\n",
       "      <td>Hyderabad/Secunderabad, New Delhi, Pune, Gurga...</td>\n",
       "      <td>Thescholar</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Intern</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Tower Research Capital</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Infogain</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, United States (USA), Bulgaria</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Benovymed Healthcare</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0                              Junior Data Scientist   \n",
       "1                                     Data Scientist   \n",
       "2  Data Scientist/ Senior Data Scientist/ Manager...   \n",
       "3                                     Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5                              Python and ML Trainer   \n",
       "6                                             Intern   \n",
       "7                          Hiring For Data Scientist   \n",
       "8                              Junior Data Scientist   \n",
       "9                           Principal Data Scientist   \n",
       "\n",
       "                                        Job_location  \\\n",
       "0  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "1              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "2  Noida, Kolkata, Mumbai, Chandigarh, Hyderabad/...   \n",
       "3  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "4                                              Noida   \n",
       "5  Hyderabad/Secunderabad, New Delhi, Pune, Gurga...   \n",
       "6                                   Gurgaon/Gurugram   \n",
       "7                                             Remote   \n",
       "8    Gurgaon/Gurugram, United States (USA), Bulgaria   \n",
       "9                                          New Delhi   \n",
       "\n",
       "                  Company_Name Experience_Required  \n",
       "0                     Analytos             0-2 Yrs  \n",
       "1                    Blackbuck             3-7 Yrs  \n",
       "2  Dreambig It Solutions India             1-6 Yrs  \n",
       "3                     Analytos             2-4 Yrs  \n",
       "4               Times Internet             3-8 Yrs  \n",
       "5                   Thescholar             3-8 Yrs  \n",
       "6       Tower Research Capital             0-1 Yrs  \n",
       "7                     Infogain             4-9 Yrs  \n",
       "8                       Adidas             1-6 Yrs  \n",
       "9         Benovymed Healthcare             2-7 Yrs  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3rd Question:\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "url='https://www.naukri.com/'\n",
    "driver.get(url)\n",
    "time.sleep(4)\n",
    "driver.maximize_window()\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,'suggestor-input')\n",
    "designation.send_keys('Data scientist')\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click()\n",
    "time.sleep(4)\n",
    "\n",
    "\n",
    "#Filtering by Location as \"Delhi/NCR\"\n",
    "\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[5]/div[2]/div[2]/label/p/span[1]')\n",
    "search.click()\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "#Filtering by Salary to \"0-3Lakhs\"\n",
    "\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/p/span[1]')\n",
    "search.click()\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "#scraping job title from the given page\n",
    "\n",
    "title=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in a[0:10]:\n",
    "    b=i.text\n",
    "    title.append(b)\n",
    "\n",
    "\n",
    "#scraping Job location from the given page\n",
    "\n",
    "location=[]\n",
    "a=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in a[0:10]:\n",
    "    b=i.text\n",
    "    location.append(b) \n",
    "\n",
    "#scraping Company name from the given page\n",
    "\n",
    "name=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in a[0:10]:\n",
    "    b=i.text\n",
    "    name.append(b)\n",
    "    \n",
    "#scraping Experience required from the given page\n",
    "\n",
    "exp=[]\n",
    "a=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in a[0:10]:\n",
    "    b=i.text\n",
    "    exp.append(b)\n",
    "\n",
    "    \n",
    "print(len(title),len(location),len(name),len(exp))\n",
    "\n",
    "c=pd.DataFrame({'Job_Title':title,'Job_location':location,'Company_Name':name,'Experience_Required':exp})\n",
    "c\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "21f1e885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>john jacobs</td>\n",
       "      <td>UV Protection Round Sunglasses (53)</td>\n",
       "      <td>‚Çπ2,249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>john jacobs</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (57)</td>\n",
       "      <td>‚Çπ1,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Cat-eye, Retro Square, Oval, Rou...</td>\n",
       "      <td>‚Çπ168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>‚Çπ194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>‚Çπ539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROZIOR</td>\n",
       "      <td>UV Protection Cat-eye Sunglasses (Free Size)</td>\n",
       "      <td>‚Çπ399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Sukart</td>\n",
       "      <td>UV Protection, Riding Glasses, Polarized, Grad...</td>\n",
       "      <td>‚Çπ281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>UV Protection Round Sunglasses (58)</td>\n",
       "      <td>‚Çπ4,613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Resist</td>\n",
       "      <td>Gradient, Riding Glasses, UV Protection, Tough...</td>\n",
       "      <td>‚Çπ1,349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Redleaf</td>\n",
       "      <td>Gradient, UV Protection Round Sunglasses (Free...</td>\n",
       "      <td>‚Çπ251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Brand                                Product Description   Price\n",
       "0   john jacobs                UV Protection Round Sunglasses (53)  ‚Çπ2,249\n",
       "1   john jacobs         UV Protection Retro Square Sunglasses (57)  ‚Çπ1,999\n",
       "2     Elligator  UV Protection Cat-eye, Retro Square, Oval, Rou...    ‚Çπ168\n",
       "3          SRPM             UV Protection Wayfarer Sunglasses (50)    ‚Çπ194\n",
       "4      Fastrack   UV Protection Rectangular Sunglasses (Free Size)    ‚Çπ539\n",
       "..          ...                                                ...     ...\n",
       "95       ROZIOR       UV Protection Cat-eye Sunglasses (Free Size)    ‚Çπ399\n",
       "96       Sukart  UV Protection, Riding Glasses, Polarized, Grad...    ‚Çπ281\n",
       "97      Ray-Ban                UV Protection Round Sunglasses (58)  ‚Çπ4,613\n",
       "98       Resist  Gradient, Riding Glasses, UV Protection, Tough...  ‚Çπ1,349\n",
       "99      Redleaf  Gradient, UV Protection Round Sunglasses (Free...    ‚Çπ251\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4th Question:\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "exit_button=driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button') #Closing pop-up while opening the page\n",
    "exit_button\n",
    "exit_button.click()\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,'_3704LK') \n",
    "designation.send_keys('sun glasses')\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,'L0Z3Pu')\n",
    "search.click()\n",
    "time.sleep(4)\n",
    "\n",
    "#Extracting details as Brand name, description and price\n",
    "\n",
    "name1=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    name1.append(b)\n",
    "name1=name1[:36]    \n",
    "product1=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    product1.append(b)\n",
    "product1=product1[:36]\n",
    "price1=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    price1.append(b)\n",
    "price1=price1[:36]\n",
    "time.sleep(5)\n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]/span')\n",
    "next_button.click()\n",
    "time.sleep(5)\n",
    "#Extracting from page 2\n",
    "name2=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    name2.append(b)\n",
    "name2=name2[:36]    \n",
    "product2=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    product2.append(b)\n",
    "product2=product2[:36]\n",
    "price2=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    price2.append(b)\n",
    "price2=price2[:36]\n",
    "time.sleep(5)\n",
    "next_button=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]/span')\n",
    "next_button.click()\n",
    "time.sleep(5)\n",
    "#Extracting from page 3\n",
    "\n",
    "name3=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    name3.append(b)\n",
    "name3=name3[:28]    \n",
    "product3=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    product3.append(b)\n",
    "product3=product3[:28]\n",
    "price3=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    price3.append(b)\n",
    "price3=price3[:28]\n",
    "\n",
    "name=[]\n",
    "name=name1+name2+name3\n",
    "product=[]\n",
    "product=product1+product2+product3\n",
    "price=[]\n",
    "price=price1+price2+price3\n",
    "print(len(name),len(product),len(price))\n",
    "\n",
    "c=pd.DataFrame({'Brand':name,'Product Description':product,'Price':price})\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "840812fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Very very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Camera is awesome\\nBest battery backup\\nA perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Value for money üòç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is amazing at all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>Excellent Phone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Quality camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Best Apple iPhone that i have bought at a very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>Exactly mach what you expect and where Spent y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Excellent product but packing was not upto mark..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Excellent camera üì∏ And Display touching very N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating         Review Summary  \\\n",
       "0       5               Terrific   \n",
       "1       5         Classy product   \n",
       "2       5      Terrific purchase   \n",
       "3       5              Wonderful   \n",
       "4       5              Brilliant   \n",
       "..    ...                    ...   \n",
       "95      5              Wonderful   \n",
       "96      5              Must buy!   \n",
       "97      5                 Super!   \n",
       "98      5     Highly recommended   \n",
       "99      5  Mind-blowing purchase   \n",
       "\n",
       "                                          Full Review  \n",
       "0                                      Very very good  \n",
       "1   Camera is awesome\\nBest battery backup\\nA perf...  \n",
       "2                                   Value for money üòç  \n",
       "3                              This is amazing at all  \n",
       "4                                    Excellent Phone.  \n",
       "..                                                ...  \n",
       "95                                     Quality camera  \n",
       "96  Best Apple iPhone that i have bought at a very...  \n",
       "97  Exactly mach what you expect and where Spent y...  \n",
       "98  Excellent product but packing was not upto mark..  \n",
       "99  Excellent camera üì∏ And Display touching very N...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question no. 5\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "url='https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZE3ENS&marketplace=FLIPKART'\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "#extracting from page\n",
    "time.sleep(3)\n",
    "rating1=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    rating1.append(b)\n",
    "summary1=[]\n",
    "a=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    summary1.append(b)\n",
    "full1=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    full1.append(b)\n",
    "time.sleep(3)\n",
    "search=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "search.click()\n",
    "\n",
    "#extracting from page 2\n",
    "time.sleep(3)\n",
    "rating2=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    rating2.append(b)\n",
    "summary2=[]\n",
    "a=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    summary2.append(b)\n",
    "full2=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    full2.append(b)\n",
    "time.sleep(3)\n",
    "search=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]/span')\n",
    "search.click()\n",
    "\n",
    "#extracting from page 3\n",
    "time.sleep(3)\n",
    "rating3=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    rating3.append(b)\n",
    "summary3=[]\n",
    "a=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    summary3.append(b)\n",
    "full3=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    full3.append(b)\n",
    "time.sleep(3)\n",
    "search=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]/span')\n",
    "search.click()\n",
    "\n",
    "#extracting from page 4\n",
    "time.sleep(3)\n",
    "rating4=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    rating4.append(b)\n",
    "summary4=[]\n",
    "a=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    summary4.append(b)\n",
    "full4=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    full4.append(b)\n",
    "time.sleep(3)\n",
    "search=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]/span')\n",
    "search.click()\n",
    "\n",
    "#extracting from page 5\n",
    "time.sleep(3)\n",
    "rating5=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    rating5.append(b)\n",
    "summary5=[]\n",
    "a=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    summary5.append(b)\n",
    "full5=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    full5.append(b)\n",
    "time.sleep(3)\n",
    "search=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]/span')\n",
    "search.click()\n",
    "\n",
    "#extracting from page 6\n",
    "time.sleep(3)\n",
    "rating6=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    rating6.append(b)\n",
    "summary6=[]\n",
    "a=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    summary6.append(b)\n",
    "full6=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    full6.append(b)\n",
    "time.sleep(3)\n",
    "search=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]/span')\n",
    "search.click()\n",
    "\n",
    "#extracting from page 7\n",
    "time.sleep(3)\n",
    "rating7=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    rating7.append(b)\n",
    "summary7=[]\n",
    "a=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    summary7.append(b)\n",
    "full7=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    full7.append(b)\n",
    "time.sleep(3)\n",
    "search=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]/span')\n",
    "search.click()\n",
    "\n",
    "#extracting from page 8\n",
    "time.sleep(3)\n",
    "rating8=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    rating8.append(b)\n",
    "summary8=[]\n",
    "a=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    summary8.append(b)\n",
    "full8=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    full8.append(b)\n",
    "time.sleep(3)\n",
    "search=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]/span')\n",
    "search.click()\n",
    "\n",
    "#extracting from page 9\n",
    "time.sleep(3)\n",
    "rating9=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    rating9.append(b)\n",
    "summary9=[]\n",
    "a=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    summary9.append(b)\n",
    "full9=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    full9.append(b)\n",
    "time.sleep(3)\n",
    "search=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]/span')\n",
    "search.click()\n",
    "\n",
    "#extracting from page 10\n",
    "time.sleep(3)\n",
    "rating10=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    rating10.append(b)\n",
    "summary10=[]\n",
    "a=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    summary10.append(b)\n",
    "full10=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    full10.append(b)\n",
    "time.sleep(3)\n",
    "\n",
    "rating=[]\n",
    "rating=rating1+rating2+rating3+rating4+rating5+rating6+rating7+rating8+rating9+rating10\n",
    "summary=[]\n",
    "summary=summary1+summary2+summary3+summary4+summary5+summary6+summary7+summary8+summary9+summary10\n",
    "full=[]\n",
    "full=full1+full2+full3+full4+full5+full6+full7+full8+full9+full10\n",
    "print(len(rating),len(summary),len(full))\n",
    "\n",
    "c=pd.DataFrame({'Rating':rating,'Review Summary':summary,'Full Review':full})\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5820688d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>!Combo Pack Of 2 Casual Shoes! Sneakers For Men</td>\n",
       "      <td>‚Çπ479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Combo Pack Of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>‚Çπ479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Synthetic Leather |Lightweight|Comfort|Summer|...</td>\n",
       "      <td>‚Çπ399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Synthetic Leather |Lightweight|Comfort|Summer|...</td>\n",
       "      <td>‚Çπ499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SFR</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Mesh |Lightweight|Comfort|Summer|Trendy|Walkin...</td>\n",
       "      <td>‚Çπ1,399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>WOODLAND</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>‚Çπ2,096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Club Culture Sneakers For Men</td>\n",
       "      <td>‚Çπ499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>‚Çπ1,449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand                                Product Description   Price\n",
       "0     BRUTON    !Combo Pack Of 2 Casual Shoes! Sneakers For Men    ‚Çπ479\n",
       "1      BIRDE      Combo Pack Of 2 Casual Shoes Sneakers For Men    ‚Çπ479\n",
       "2       aadi  Synthetic Leather |Lightweight|Comfort|Summer|...    ‚Çπ399\n",
       "3       aadi  Synthetic Leather |Lightweight|Comfort|Summer|...    ‚Çπ499\n",
       "4        SFR                                   Sneakers For Men    ‚Çπ348\n",
       "..       ...                                                ...     ...\n",
       "95  RED TAPE  Mesh |Lightweight|Comfort|Summer|Trendy|Walkin...  ‚Çπ1,399\n",
       "96      aadi                                   Sneakers For Men    ‚Çπ499\n",
       "97  WOODLAND                                   Sneakers For Men  ‚Çπ2,096\n",
       "98      aadi                      Club Culture Sneakers For Men    ‚Çπ499\n",
       "99  RED TAPE                                 Sneakers For Women  ‚Çπ1,449\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6th Question:\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "exit_button=driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button') #Closing pop-up while opening the page\n",
    "exit_button\n",
    "exit_button.click()\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,'_3704LK') \n",
    "designation.send_keys('sneaker')\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,'L0Z3Pu')\n",
    "search.click()\n",
    "\n",
    "#extracting from page\n",
    "\n",
    "time.sleep(3)\n",
    "brand1=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    brand1.append(b)\n",
    "brand1=brand1[:33]\n",
    "desc1=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    desc1.append(b)\n",
    "desc1=desc1[:33]    \n",
    "price1=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    price1.append(b)\n",
    "price1=price1[:33]    \n",
    "time.sleep(3)\n",
    "search=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "search.click()\n",
    "\n",
    "#extracting from page 2\n",
    "\n",
    "time.sleep(3)\n",
    "brand2=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    brand2.append(b)\n",
    "brand2=brand2[:33]\n",
    "desc2=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    desc2.append(b)\n",
    "desc2=desc2[:33]    \n",
    "price2=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    price2.append(b)\n",
    "price2=price2[:33]    \n",
    "time.sleep(3)\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]/span')\n",
    "search.click()\n",
    "\n",
    "#extracting from page 3\n",
    "\n",
    "time.sleep(3)\n",
    "brand3=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    brand3.append(b)\n",
    "brand3=brand3[:34]\n",
    "desc3=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    desc3.append(b)\n",
    "desc3=desc3[:34]    \n",
    "price3=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    price3.append(b)\n",
    "price3=price3[:34]    \n",
    "time.sleep(3)\n",
    "\n",
    "brand=[]\n",
    "brand=brand1+brand2+brand3\n",
    "desc=[]\n",
    "desc=desc1+desc2+desc3\n",
    "price=[]\n",
    "price=price1+price2+price3\n",
    "\n",
    "print(len(brand),len(desc),len(price))\n",
    "\n",
    "c=pd.DataFrame({'Brand':brand,'Product Description':desc,'Price':price})\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffd7fac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer Aspire Lite AMD Ryzen 5 5500U Premium Thi...</td>\n",
       "      <td>40,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer One 14 Laptop Intel Core i5 1135G7 (8GB R...</td>\n",
       "      <td>42,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acer Aspire Lite 11th Gen Intel Core i3-1115G4...</td>\n",
       "      <td>32,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP 15s,11th Gen Intel Core i3-1115G4 8GB RAM/5...</td>\n",
       "      <td>39,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Core i3 11th Gen 1...</td>\n",
       "      <td>36,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo IdeaPad 3 11th Gen Intel Core i3 15.6\" ...</td>\n",
       "      <td>37,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS [Smart Choice] Vivobook 15, Intel Celeron...</td>\n",
       "      <td>30,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Acer Aspire Lite 11th Gen Intel Core i5-1155G7...</td>\n",
       "      <td>45,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dell Vostro 3420 Laptop,Intel i5-1135G7/8GB/51...</td>\n",
       "      <td>49,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Laptop 15s, 12th Gen Intel Core i3-1215U, 1...</td>\n",
       "      <td>41,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   Price\n",
       "0  Acer Aspire Lite AMD Ryzen 5 5500U Premium Thi...  40,990\n",
       "1  Acer One 14 Laptop Intel Core i5 1135G7 (8GB R...  42,990\n",
       "2  Acer Aspire Lite 11th Gen Intel Core i3-1115G4...  32,990\n",
       "3  HP 15s,11th Gen Intel Core i3-1115G4 8GB RAM/5...  39,990\n",
       "4  Lenovo IdeaPad Slim 3 Intel Core i3 11th Gen 1...  36,990\n",
       "5  Lenovo IdeaPad 3 11th Gen Intel Core i3 15.6\" ...  37,800\n",
       "6  ASUS [Smart Choice] Vivobook 15, Intel Celeron...  30,990\n",
       "7  Acer Aspire Lite 11th Gen Intel Core i5-1155G7...  45,990\n",
       "8  Dell Vostro 3420 Laptop,Intel i5-1135G7/8GB/51...  49,490\n",
       "9  HP Laptop 15s, 12th Gen Intel Core i3-1215U, 1...  41,990"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question no. 7\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "url='https://www.amazon.in/'\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "\n",
    "#Searching by term Laptop\n",
    "\n",
    "designation=driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input') \n",
    "designation.send_keys('Laptop')\n",
    "\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search.click()\n",
    "time.sleep(3)\n",
    "\n",
    "#Extracting Brand\n",
    "brand=[]\n",
    "a=driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    brand.append(b)\n",
    "brand=brand[:10]\n",
    "time.sleep(3)\n",
    "\n",
    "#Extracting price\n",
    "\n",
    "price=[]\n",
    "a=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in a:\n",
    "    price.append(i.text)\n",
    "price=price[:10] \n",
    "\n",
    "print(len(brand),len(price))\n",
    "c=pd.DataFrame({'Title':brand,'Price':price})\n",
    "c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a762229d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type of Quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Inspirational, Leadership, Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Quote              Author  \\\n",
       "0    The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "..                                                 ...                 ...   \n",
       "995  Regret for the things we did can be tempered b...    Sydney J. Harris   \n",
       "996  America... just a nation of two hundred millio...  Hunter S. Thompson   \n",
       "997  For every disciplined effort there is a multip...            Jim Rohn   \n",
       "998  The spiritual journey is individual, highly pe...            Ram Dass   \n",
       "999  The mind is not a vessel to be filled but a fi...            Plutarch   \n",
       "\n",
       "                                Type of Quote  \n",
       "0    Essence, Deep Thought, Transcendentalism  \n",
       "1                   Inspiration, Past, Trying  \n",
       "2                         Country, Peace, War  \n",
       "3          Inspirational, Motivational, Death  \n",
       "4                4th Of July, Food, Patriotic  \n",
       "..                                        ...  \n",
       "995         Love, Inspirational, Motivational  \n",
       "996                    Gun, Two, Qualms About  \n",
       "997     Inspirational, Greatness, Best Effort  \n",
       "998                    Spiritual, Truth, Yoga  \n",
       "999      Inspirational, Leadership, Education  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question no. 8:\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "url='https://www.azquotes.com/'\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a')\n",
    "search.click()\n",
    "time.sleep(3)\n",
    "\n",
    "#Extracting from page 1\n",
    "\n",
    "quote1=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    quote1.append(b)\n",
    "author1=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    author1.append(b) \n",
    "type1=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    type1.append(b)\n",
    "\n",
    "# Extracting from page 2\n",
    "\n",
    "time.sleep(2)\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[3]/a')\n",
    "search.click()\n",
    "time.sleep(3)\n",
    "\n",
    "quote2=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    quote2.append(b)\n",
    "author2=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    author2.append(b)   \n",
    "type2=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    type2.append(b)\n",
    "    \n",
    "# Extracting from page 3\n",
    "\n",
    "time.sleep(2)\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[5]/a')\n",
    "search.click()\n",
    "time.sleep(3)\n",
    "\n",
    "quote3=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    quote3.append(b)\n",
    "author3=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    author3.append(b)   \n",
    "type3=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    type3.append(b)\n",
    "    \n",
    "# Extracting from page 4\n",
    "\n",
    "time.sleep(2)\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[6]/a')\n",
    "search.click()\n",
    "time.sleep(3)\n",
    "\n",
    "quote4=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    quote4.append(b)\n",
    "author4=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    author4.append(b)   \n",
    "type4=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    type4.append(b)\n",
    "    \n",
    "# Extracting from page 5\n",
    "\n",
    "time.sleep(2)\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[7]/a')\n",
    "search.click()\n",
    "time.sleep(3)\n",
    "\n",
    "quote5=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    quote5.append(b)\n",
    "author5=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    author5.append(b)   \n",
    "type5=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    type5.append(b)\n",
    "    \n",
    "# Extracting from page 6\n",
    "\n",
    "time.sleep(2)\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[8]/a')\n",
    "search.click()\n",
    "time.sleep(3)\n",
    "\n",
    "quote6=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    quote6.append(b)\n",
    "author6=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    author6.append(b)   \n",
    "type6=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    type6.append(b)\n",
    "    \n",
    "# Extracting from page 7\n",
    "\n",
    "time.sleep(2)\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[9]/a')\n",
    "search.click()\n",
    "time.sleep(3)\n",
    "\n",
    "quote7=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    quote7.append(b)\n",
    "author7=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    author7.append(b)   \n",
    "type7=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    type7.append(b)\n",
    "    \n",
    "# Extracting from page 8\n",
    "\n",
    "time.sleep(2)\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[10]/a')\n",
    "search.click()\n",
    "time.sleep(3)\n",
    "\n",
    "quote8=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    quote8.append(b)\n",
    "author8=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    author8.append(b)   \n",
    "type8=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    type8.append(b)\n",
    "    \n",
    "# Extracting from page 9\n",
    "\n",
    "time.sleep(2)\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[11]/a')\n",
    "search.click()\n",
    "time.sleep(3)\n",
    "\n",
    "quote9=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    quote9.append(b)\n",
    "author9=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    author9.append(b)   \n",
    "type9=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    type9.append(b)\n",
    "\n",
    "# Extracting from page 10\n",
    "\n",
    "time.sleep(2)\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]/a')\n",
    "search.click()\n",
    "time.sleep(3)\n",
    "\n",
    "quote10=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    quote10.append(b)\n",
    "author10=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    author10.append(b)   \n",
    "type10=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    type10.append(b)\n",
    "\n",
    "quote=[]\n",
    "quote=quote1+quote2+quote3+quote4+quote5+quote6+quote7+quote8+quote9+quote10\n",
    "author=[]\n",
    "author=author1+author2+author3+author4+author5+author6+author7+author8+author9+author10\n",
    "typed=[]\n",
    "typed=type1+type2+type3+type4+type5+type6+type7+type8+type9+type10\n",
    "\n",
    "print(len(quote),len(author),len(typed))\n",
    "\n",
    "c=pd.DataFrame({'Quote':quote,'Author':author,'Type of Quote':typed})\n",
    "c\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c6460c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 19 19 19\n"
     ]
    }
   ],
   "source": [
    "# Question no. 9\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "url='https://www.jagranjosh.com/'\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(8)\n",
    "\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div/div[1]/div/div[5]/div/div[1]/header/div[3]/ul/li[3]/a')\n",
    "search.click()\n",
    "time.sleep(6)\n",
    "\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a')\n",
    "search.click()\n",
    "time.sleep(6)\n",
    "\n",
    "# One\n",
    "\n",
    "name1=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 150px; height: 121px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    name1.append(b)\n",
    "\n",
    "\n",
    "born1=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 105px; height: 121px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    born1.append(b)\n",
    "\n",
    "\n",
    "term1=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 256px; height: 121px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    term1.append(b)\n",
    "\n",
    "remark1=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 145px; height: 121px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    remark1.append(b)\n",
    "    \n",
    "# Two\n",
    "\n",
    "name2=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 150px; height: 80px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    name2.append(b)\n",
    "name2\n",
    "\n",
    "born2=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 105px; height: 80px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    born2.append(b)\n",
    "\n",
    "\n",
    "term2=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 256px; height: 80px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    term2.append(b)\n",
    "\n",
    "remark2=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 145px; height: 80px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    remark2.append(b)\n",
    "    \n",
    "# Three\n",
    "\n",
    "name3=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 150px; height: 104px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    name3.append(b)\n",
    "\n",
    "born3=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 105px; height: 104px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    born3.append(b)\n",
    "\n",
    "\n",
    "term3=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 256px; height: 104px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    term3.append(b)\n",
    "\n",
    "remark3=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 145px; height: 104px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    remark3.append(b)\n",
    "    \n",
    "# Four\n",
    "\n",
    "name4=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 150px; height: 87px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    name4.append(b)\n",
    "\n",
    "born4=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 105px; height: 87px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    born4.append(b)\n",
    "\n",
    "\n",
    "term4=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 256px; height: 87px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    term4.append(b)\n",
    "\n",
    "remark4=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 145px; height: 87px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    remark4.append(b)\n",
    "    \n",
    "# Five\n",
    "\n",
    "name5=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 150px; height: 97px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    name5.append(b)\n",
    "\n",
    "born5=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 105px; height: 97px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    born5.append(b)\n",
    "\n",
    "\n",
    "term5=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 256px; height: 97px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    term5.append(b)\n",
    "\n",
    "remark5=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 145px; height: 97px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    remark5.append(b)\n",
    "    \n",
    "# Six\n",
    "\n",
    "name6=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 150px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    name6.append(b)\n",
    "    \n",
    "born6=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 105px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    born6.append(b)\n",
    "\n",
    "\n",
    "term6=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 256px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    term6.append(b)\n",
    "\n",
    "remark6=[]\n",
    "a=driver.find_elements(By.XPATH,'//td[@style=\"width: 145px;\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    remark6.append(b)\n",
    "    \n",
    "name=[]\n",
    "name=name1+name2+name3+name4+name5+name6\n",
    "born=[]\n",
    "born=born1+born2+born3+born4+born5+born6\n",
    "term=[]\n",
    "term=term1+term2+term3+term4+term5+term6\n",
    "remark=[]\n",
    "remark=remark1+remark2+remark3+remark4+remark5+remark6\n",
    "\n",
    "print(len(name),len(born),len(term),len(remark))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92e528a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM Name</th>\n",
       "      <th>Born-Dead</th>\n",
       "      <th>Term of office</th>\n",
       "      <th>Remark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>(1889‚Äì1964)</td>\n",
       "      <td>15 August 1947 to 27 May 1964\\n16 years, 286 days</td>\n",
       "      <td>The first prime minister of India and the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lal Bahadur Shastri</td>\n",
       "      <td>(1904‚Äì1966)</td>\n",
       "      <td>9 June 1964 to 11 January 1966\\n1 year, 216 days</td>\n",
       "      <td>He has given the slogan of 'Jai Jawan Jai Kisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gulzarilal Nanda (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>27 May 1964 to 9 June 1964,\\n13 days</td>\n",
       "      <td>First acting PM of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gulzari Lal Nanda  (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>11 January 1966 to 24 January 1966\\n13 days</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917‚Äì1984)</td>\n",
       "      <td>24 January 1966 to 24 March 1977\\n11 years, 59...</td>\n",
       "      <td>First female Prime Minister of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Charan Singh</td>\n",
       "      <td>(1902‚Äì1987)</td>\n",
       "      <td>28 July 1979 to 14 January 1980\\n170 days</td>\n",
       "      <td>Only PM who did not face the Parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rajiv Gandhi</td>\n",
       "      <td>(1944‚Äì1991)</td>\n",
       "      <td>31 October 1984 to 2 December 1989\\n5 years, 3...</td>\n",
       "      <td>Youngest to become PM (40 years old)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P. V. Narasimha Rao</td>\n",
       "      <td>(1921‚Äì2004)</td>\n",
       "      <td>21 June 1991 to 16 May 1996\\n4 years, 330 days</td>\n",
       "      <td>First PM from South India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924- 2018)</td>\n",
       "      <td>16 May 1996 to 1 June 1996\\n16 days</td>\n",
       "      <td>PM for shortest tenure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>H. D. Deve Gowda</td>\n",
       "      <td>(born 1933)</td>\n",
       "      <td>1 June 1996 to 21 April 1997\\n324 days</td>\n",
       "      <td>He belongs to  Janata Dal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Inder Kumar Gujral</td>\n",
       "      <td>(1919‚Äì2012)</td>\n",
       "      <td>21 April 1997 to 19 March 1998 \\n332 days</td>\n",
       "      <td>------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Manmohan Singh</td>\n",
       "      <td>(born 1932)</td>\n",
       "      <td>22 May 2004 to 26 May 2014   \\n10 years, 4 days</td>\n",
       "      <td>First Sikh PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Morarji Desai</td>\n",
       "      <td>(1896‚Äì1995)</td>\n",
       "      <td>24 March 1977 to  28 July 1979 \\n2 year, 126 days</td>\n",
       "      <td>Oldest to become PM (81 years old) and first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924-2018)</td>\n",
       "      <td>19 March 1998 to 22 May 2004 \\n6 years, 64 days</td>\n",
       "      <td>The first non-congress PM who completed a ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>26 May 2014 - 2019</td>\n",
       "      <td>4th Prime Minister of India who served two con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917‚Äì1984)</td>\n",
       "      <td>14 January 1980 to 31 October 1984\\n4 years, 2...</td>\n",
       "      <td>The first lady who served as PM for the second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chandra Shekhar</td>\n",
       "      <td>(1927‚Äì2007)</td>\n",
       "      <td>10 November 1990 to 21 June 1991\\n223 days</td>\n",
       "      <td>He belongs to  Samajwadi Janata Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>V. P. Singh</td>\n",
       "      <td>(1931‚Äì2008)</td>\n",
       "      <td>2 December 1989 to 10 November 1990\\n343 days</td>\n",
       "      <td>First PM to step down after a vote of no confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>30 May 2019- Incumbent</td>\n",
       "      <td>First non-congress PM with two consecutive ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        PM Name     Born-Dead  \\\n",
       "0             Jawahar Lal Nehru   (1889‚Äì1964)   \n",
       "1           Lal Bahadur Shastri   (1904‚Äì1966)   \n",
       "2     Gulzarilal Nanda (Acting)   (1898-1998)   \n",
       "3   Gulzari Lal Nanda  (Acting)   (1898-1998)   \n",
       "4                 Indira Gandhi   (1917‚Äì1984)   \n",
       "5                  Charan Singh   (1902‚Äì1987)   \n",
       "6                  Rajiv Gandhi   (1944‚Äì1991)   \n",
       "7           P. V. Narasimha Rao   (1921‚Äì2004)   \n",
       "8          Atal Bihari Vajpayee  (1924- 2018)   \n",
       "9              H. D. Deve Gowda   (born 1933)   \n",
       "10           Inder Kumar Gujral   (1919‚Äì2012)   \n",
       "11               Manmohan Singh   (born 1932)   \n",
       "12                Morarji Desai   (1896‚Äì1995)   \n",
       "13         Atal Bihari Vajpayee   (1924-2018)   \n",
       "14                Narendra Modi   (born 1950)   \n",
       "15                Indira Gandhi   (1917‚Äì1984)   \n",
       "16              Chandra Shekhar   (1927‚Äì2007)   \n",
       "17                  V. P. Singh   (1931‚Äì2008)   \n",
       "18                Narendra Modi   (born 1950)   \n",
       "\n",
       "                                       Term of office  \\\n",
       "0   15 August 1947 to 27 May 1964\\n16 years, 286 days   \n",
       "1    9 June 1964 to 11 January 1966\\n1 year, 216 days   \n",
       "2                27 May 1964 to 9 June 1964,\\n13 days   \n",
       "3         11 January 1966 to 24 January 1966\\n13 days   \n",
       "4   24 January 1966 to 24 March 1977\\n11 years, 59...   \n",
       "5           28 July 1979 to 14 January 1980\\n170 days   \n",
       "6   31 October 1984 to 2 December 1989\\n5 years, 3...   \n",
       "7      21 June 1991 to 16 May 1996\\n4 years, 330 days   \n",
       "8                 16 May 1996 to 1 June 1996\\n16 days   \n",
       "9              1 June 1996 to 21 April 1997\\n324 days   \n",
       "10          21 April 1997 to 19 March 1998 \\n332 days   \n",
       "11    22 May 2004 to 26 May 2014   \\n10 years, 4 days   \n",
       "12  24 March 1977 to  28 July 1979 \\n2 year, 126 days   \n",
       "13    19 March 1998 to 22 May 2004 \\n6 years, 64 days   \n",
       "14                                 26 May 2014 - 2019   \n",
       "15  14 January 1980 to 31 October 1984\\n4 years, 2...   \n",
       "16         10 November 1990 to 21 June 1991\\n223 days   \n",
       "17      2 December 1989 to 10 November 1990\\n343 days   \n",
       "18                             30 May 2019- Incumbent   \n",
       "\n",
       "                                               Remark  \n",
       "0   The first prime minister of India and the long...  \n",
       "1   He has given the slogan of 'Jai Jawan Jai Kisa...  \n",
       "2                            First acting PM of India  \n",
       "3                                                   -  \n",
       "4                First female Prime Minister of India  \n",
       "5             Only PM who did not face the Parliament  \n",
       "6                Youngest to become PM (40 years old)  \n",
       "7                           First PM from South India  \n",
       "8                              PM for shortest tenure  \n",
       "9                           He belongs to  Janata Dal  \n",
       "10                                             ------  \n",
       "11                                      First Sikh PM  \n",
       "12  Oldest to become PM (81 years old) and first t...  \n",
       "13   The first non-congress PM who completed a ful...  \n",
       "14  4th Prime Minister of India who served two con...  \n",
       "15  The first lady who served as PM for the second...  \n",
       "16              He belongs to  Samajwadi Janata Party  \n",
       "17  First PM to step down after a vote of no confi...  \n",
       "18  First non-congress PM with two consecutive ten...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame with the above information\n",
    "\n",
    "c=pd.DataFrame({'PM Name':name,'Born-Dead':born,'Term of office':term,'Remark':remark})\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ccc3017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car_Name</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>De Tomaso P72</td>\n",
       "      <td>Price: $1.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ferrari LaFerrari</td>\n",
       "      <td>Price: $1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pagani Huayra</td>\n",
       "      <td>Price: $1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>McLaren Elva</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Czinger 21C</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ferrari Monza</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gordon Murray T.33</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Koenigsegg Gemera</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zenvo TSR-S</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hennessey Venom F5</td>\n",
       "      <td>Price: $1.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bentley Bacalar</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hispano Suiza Carmen Boulogne</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bentley Mulliner Batur</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Deus Vayanne</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SSC Tuatara</td>\n",
       "      <td>Price: $2.0 Million*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lotus Evija</td>\n",
       "      <td>Price: $2.1 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Aston Martin Vulcan</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Delage D12</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>McLaren Speedtail</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Rimac Nevera</td>\n",
       "      <td>Price: $2.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pagani Utopia</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pininfarina Battista</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ferrari FXX K Evo</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Gordon Murray T.50</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Lamborghini Countach</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Mercedes-AMG Project One</td>\n",
       "      <td>Price: $2.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Aston Martin Victor</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hennessey Venom F5 Roadster</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Koenigsegg Jesko</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Aston Martin Valkyrie</td>\n",
       "      <td>Price: $3.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>W Motors Lykan Hypersport</td>\n",
       "      <td>Price: $3.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>McLaren Solus</td>\n",
       "      <td>$3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Pagani Huayra Roadster BC</td>\n",
       "      <td>$3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Bugatti Chiron Pur Sport</td>\n",
       "      <td>Price: $3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lamborghini Sian</td>\n",
       "      <td>Price: $3.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Koenigsegg CC850</td>\n",
       "      <td>Price: $3.6 million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Bugatti Chiron Super Sport 300+</td>\n",
       "      <td>Price: $3.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Lamborghini Veneno</td>\n",
       "      <td>Price: $3.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Bugatti Bolide</td>\n",
       "      <td>Price: $4.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bugatti Mistral</td>\n",
       "      <td>Price: $4.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Pagani Huayra Imola</td>\n",
       "      <td>Price: $5.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Bugatti Divo</td>\n",
       "      <td>Price: $5.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SP Automotive Chaos</td>\n",
       "      <td>Price: $5.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Pagani Codalunga</td>\n",
       "      <td>Price: $6.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Mercedes-Maybach Exelero</td>\n",
       "      <td>Price: $7.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Bugatti Centodieci</td>\n",
       "      <td>Price: $8.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Bugatti Chiron Profil√©e</td>\n",
       "      <td>Price: $9.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Rolls-Royce Sweptail</td>\n",
       "      <td>Price: $10.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Bugatti La Voiture Noire</td>\n",
       "      <td>Price: $12.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rolls-Royce Boat Tail*</td>\n",
       "      <td>Price: $13.4 Million</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Car_Name                 Price\n",
       "0                     De Tomaso P72   Price: $1.3 Million\n",
       "1                 Ferrari LaFerrari   Price: $1.4 Million\n",
       "2                     Pagani Huayra   Price: $1.4 Million\n",
       "3                      McLaren Elva   Price: $1.7 Million\n",
       "4                       Czinger 21C   Price: $1.7 Million\n",
       "5                     Ferrari Monza   Price: $1.7 Million\n",
       "6                Gordon Murray T.33   Price: $1.7 Million\n",
       "7                 Koenigsegg Gemera   Price: $1.7 Million\n",
       "8                       Zenvo TSR-S   Price: $1.7 Million\n",
       "9                Hennessey Venom F5   Price: $1.8 Million\n",
       "10                  Bentley Bacalar   Price: $1.9 Million\n",
       "11    Hispano Suiza Carmen Boulogne   Price: $1.9 Million\n",
       "12           Bentley Mulliner Batur   Price: $2.0 Million\n",
       "13                     Deus Vayanne   Price: $2.0 Million\n",
       "14                      SSC Tuatara  Price: $2.0 Million*\n",
       "15                      Lotus Evija   Price: $2.1 Million\n",
       "16              Aston Martin Vulcan   Price: $2.3 Million\n",
       "17                       Delage D12   Price: $2.3 Million\n",
       "18                McLaren Speedtail   Price: $2.3 Million\n",
       "19                     Rimac Nevera   Price: $2.4 Million\n",
       "20                    Pagani Utopia   Price: $2.5 Million\n",
       "21             Pininfarina Battista   Price: $2.5 Million\n",
       "22                Ferrari FXX K Evo   Price: $2.6 Million\n",
       "23               Gordon Murray T.50   Price: $2.6 Million\n",
       "24             Lamborghini Countach   Price: $2.6 Million\n",
       "25         Mercedes-AMG Project One   Price: $2.7 Million\n",
       "26              Aston Martin Victor   Price: $3.0 Million\n",
       "27      Hennessey Venom F5 Roadster          $3.0 Million\n",
       "28                 Koenigsegg Jesko   Price: $3.0 Million\n",
       "29            Aston Martin Valkyrie   Price: $3.2 Million\n",
       "30        W Motors Lykan Hypersport   Price: $3.4 Million\n",
       "31                    McLaren Solus          $3.5 Million\n",
       "32        Pagani Huayra Roadster BC          $3.5 Million\n",
       "33         Bugatti Chiron Pur Sport   Price: $3.5 Million\n",
       "34                 Lamborghini Sian   Price: $3.6 Million\n",
       "35                 Koenigsegg CC850   Price: $3.6 million\n",
       "36  Bugatti Chiron Super Sport 300+   Price: $3.7 Million\n",
       "37               Lamborghini Veneno   Price: $3.9 Million\n",
       "38                   Bugatti Bolide   Price: $4.5 Million\n",
       "39                  Bugatti Mistral   Price: $4.7 Million\n",
       "40              Pagani Huayra Imola   Price: $5.0 Million\n",
       "41                     Bugatti Divo   Price: $5.4 Million\n",
       "42              SP Automotive Chaos   Price: $5.8 Million\n",
       "43                 Pagani Codalunga   Price: $6.4 Million\n",
       "44         Mercedes-Maybach Exelero   Price: $7.4 Million\n",
       "45               Bugatti Centodieci   Price: $8.0 Million\n",
       "46          Bugatti Chiron Profil√©e   Price: $9.0 Million\n",
       "47             Rolls-Royce Sweptail  Price: $10.8 Million\n",
       "48         Bugatti La Voiture Noire  Price: $12.8 Million\n",
       "49           Rolls-Royce Boat Tail*  Price: $13.4 Million"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question no. 10:\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.motor1.com/\")\n",
    "\n",
    "driver.maximize_window()\n",
    "time.sleep(6)\n",
    "\n",
    "designation=driver.find_element(By.XPATH,'/html/body/div[10]/div[2]/div/div/div[3]/div/div/div/form/input') \n",
    "designation.send_keys('50 most expensive cars')\n",
    "\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[10]/div[2]/div/div/div[3]/div/div/div/form/button[1]')\n",
    "search.click()\n",
    "time.sleep(3)\n",
    "\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[10]/div[9]/div/div[1]/div/div/div[2]/div/div[1]/h3/a')\n",
    "search.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# Extracting Car titles\n",
    "\n",
    "carname=[]\n",
    "a=driver.find_elements(By.XPATH,'//h3[@class=\"subheader\"]')\n",
    "for i in a:\n",
    "    b=i.text\n",
    "    carname.append(b)\n",
    "carname=carname[:50] \n",
    "\n",
    "# Extracting Price\n",
    "\n",
    "a=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[4]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a.append(c)\n",
    "a1=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[6]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a1.append(c)\n",
    "a2=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[8]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a2.append(c)\n",
    "a3=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[10]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a3.append(c)\n",
    "a4=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[12]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a4.append(c)\n",
    "a5=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[14]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a5.append(c)\n",
    "a6=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[16]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a6.append(c) \n",
    "a7=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[18]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a7.append(c)  \n",
    "a8=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[20]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a8.append(c)  \n",
    "a9=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[22]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a9.append(c)   \n",
    "a10=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[24]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a10.append(c)\n",
    "a11=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[26]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a11.append(c) \n",
    "a12=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[28]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a12.append(c)  \n",
    "a13=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[30]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a13.append(c)\n",
    "a14=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[32]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a14.append(c)\n",
    "a15=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[34]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a15.append(c) \n",
    "a16=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[36]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a16.append(c)  \n",
    "a17=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[38]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a17.append(c)\n",
    "a18=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[40]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a18.append(c)\n",
    "a19=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[42]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a19.append(c) \n",
    "a20=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[44]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a20.append(c)  \n",
    "a21=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[46]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a21.append(c)\n",
    "a22=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[48]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a22.append(c)\n",
    "a23=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[50]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a23.append(c) \n",
    "a24=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[52]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a24.append(c)  \n",
    "a25=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[54]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a25.append(c)\n",
    "a26=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[56]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a26.append(c)\n",
    "a27=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[58]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a27.append(c) \n",
    "a28=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[60]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a28.append(c)  \n",
    "a29=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[62]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a29.append(c)\n",
    "a30=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[64]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a30.append(c)\n",
    "a31=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[66]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a31.append(c) \n",
    "a32=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[68]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a32.append(c)  \n",
    "a33=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[70]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a33.append(c)\n",
    "a34=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[72]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a34.append(c)\n",
    "a35=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[74]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a35.append(c) \n",
    "a36=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[76]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a36.append(c)  \n",
    "a37=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[78]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a37.append(c)\n",
    "a38=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[80]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a38.append(c)\n",
    "a39=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[82]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a39.append(c) \n",
    "a40=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[84]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a40.append(c)  \n",
    "a41=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[86]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a41.append(c)\n",
    "a42=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[88]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a42.append(c)\n",
    "a43=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[90]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a43.append(c) \n",
    "a44=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[92]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a44.append(c)  \n",
    "a45=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[94]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a45.append(c)\n",
    "a46=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[96]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a46.append(c)\n",
    "a47=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[98]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a47.append(c) \n",
    "a48=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[100]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a48.append(c)  \n",
    "a49=[]\n",
    "b=driver.find_elements(By.XPATH,'/html/body/div[10]/div[7]/div[2]/div[1]/div[2]/div[1]/p[102]/strong')\n",
    "for i in b:\n",
    "    c=i.text\n",
    "    a49.append(c)\n",
    "    \n",
    "price=[]\n",
    "price=a+a1+a2+a3+a4+a5+a6+a7+a8+a9+a10+a11+a12+a13+a14+a15+a16+a17+a18+a19+a20+a21+a22+a23+a24+a25+a26+a27+a28+a29+a30+a31+a31+a32+a33+a34+a35+a36+a37+a38+a39+a40+a41+a42+a43+a44+a45+a46+a47+a48+a49\n",
    "price=price[:50]\n",
    "\n",
    "print(len(carname),len(price))\n",
    "\n",
    "c=pd.DataFrame({'Car_Name':carname,'Price':price})\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f49ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
