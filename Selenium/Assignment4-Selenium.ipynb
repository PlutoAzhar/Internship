{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "615c7b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: bs4 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from bs4) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.4)\n",
      "Requirement already satisfied: requests in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (2.29.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\azhar1\\anaconda3\\lib\\site-packages (from requests) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, ElementClickInterceptedException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0acec2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video_Name</th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Upload_Date</th>\n",
       "      <th>Views_in_Billions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - children's songs</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>13.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids - nursery rhymes</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Bath Song</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.</td>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.</td>\n",
       "      <td>Phonics Song with Two Words</td>\n",
       "      <td>ChuChu TV - children's songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>Learning Colors – Colorful Eggs on a Farm</td>\n",
       "      <td>Miroshka TV - children's songs</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>Masha and the Bear – Recipe for Disaster</td>\n",
       "      <td>Get Movies - children's songs</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>Axel F</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>Roar</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>Baa Baa Black Sheep</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>Lakdi Ki Kathi</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>Humpty the train on a fruits ride</td>\n",
       "      <td>Kiddiestv Hindi - children's songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>Bailando</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                 Video_Name  \\\n",
       "0    1.                           Baby Shark Dance   \n",
       "1    2.                                  Despacito   \n",
       "2    3.                       Johny Johny Yes Papa   \n",
       "3    4.                                  Bath Song   \n",
       "4    5.                               Shape of You   \n",
       "5    6.                              See You Again   \n",
       "6    8.                          Wheels on the Bus   \n",
       "7    7.                Phonics Song with Two Words   \n",
       "8    9.                                Uptown Funk   \n",
       "9   10.  Learning Colors – Colorful Eggs on a Farm   \n",
       "10  11.                              Gangnam Style   \n",
       "11  12.   Masha and the Bear – Recipe for Disaster   \n",
       "12  13.                             Dame Tu Cosita   \n",
       "13  14.                                     Axel F   \n",
       "14  15.                                      Sugar   \n",
       "15  16.                                       Roar   \n",
       "16  17.                             Counting Stars   \n",
       "17  18.                        Baa Baa Black Sheep   \n",
       "18  19.                                      Sorry   \n",
       "19  20.           Waka Waka (This Time for Africa)   \n",
       "20  21.                          Thinking Out Loud   \n",
       "21  22.                             Lakdi Ki Kathi   \n",
       "22  23.                                 Dark Horse   \n",
       "23  24.                                    Perfect   \n",
       "24  25.                                      Faded   \n",
       "25  26.                                 Let Her Go   \n",
       "26  27.          Humpty the train on a fruits ride   \n",
       "27  28.                             Girls Like You   \n",
       "28  29.                                   Bailando   \n",
       "29  30.                                    Lean On   \n",
       "\n",
       "                               Artist_Name        Upload_Date  \\\n",
       "0   Pinkfong Baby Shark - children's songs      June 17, 2016   \n",
       "1                               Luis Fonsi   January 12, 2017   \n",
       "2             LooLoo Kids - nursery rhymes    October 8, 2016   \n",
       "3               Cocomelon - nursery rhymes        May 2, 2018   \n",
       "4                               Ed Sheeran   January 30, 2017   \n",
       "5                              Wiz Khalifa      April 6, 2015   \n",
       "6               Cocomelon - nursery rhymes       May 24, 2018   \n",
       "7             ChuChu TV - children's songs      March 6, 2014   \n",
       "8                              Mark Ronson  November 19, 2014   \n",
       "9           Miroshka TV - children's songs  February 27, 2018   \n",
       "10                                     Psy      July 15, 2012   \n",
       "11           Get Movies - children's songs   January 31, 2012   \n",
       "12                               El Chombo      April 5, 2018   \n",
       "13                              Crazy Frog      June 16, 2009   \n",
       "14                                Maroon 5   January 14, 2015   \n",
       "15                              Katy Perry  September 5, 2013   \n",
       "16                             OneRepublic       May 31, 2013   \n",
       "17              Cocomelon - nursery rhymes      June 25, 2018   \n",
       "18                           Justin Bieber   October 22, 2015   \n",
       "19                                 Shakira       June 4, 2010   \n",
       "20                              Ed Sheeran    October 7, 2014   \n",
       "21                            Jingle Toons      June 14, 2018   \n",
       "22                              Katy Perry  February 20, 2014   \n",
       "23                              Ed Sheeran   November 9, 2017   \n",
       "24                             Alan Walker   December 3, 2015   \n",
       "25                               Passenger      July 25, 2012   \n",
       "26      Kiddiestv Hindi - children's songs   January 26, 2018   \n",
       "27                                Maroon 5       May 31, 2018   \n",
       "28                        Enrique Iglesias     April 11, 2014   \n",
       "29                             Major Lazer     March 22, 2015   \n",
       "\n",
       "   Views_in_Billions  \n",
       "0              13.18  \n",
       "1               8.23  \n",
       "2               6.76  \n",
       "3               6.33  \n",
       "4               6.05  \n",
       "5               5.98  \n",
       "6               5.46  \n",
       "7               5.42  \n",
       "8               4.99  \n",
       "9               4.94  \n",
       "10              4.86  \n",
       "11              4.55  \n",
       "12              4.41  \n",
       "13              4.00  \n",
       "14              3.91  \n",
       "15              3.84  \n",
       "16              3.84  \n",
       "17              3.73  \n",
       "18              3.69  \n",
       "19              3.68  \n",
       "20              3.63  \n",
       "21              3.63  \n",
       "22              3.56  \n",
       "23              3.51  \n",
       "24              3.49  \n",
       "25              3.48  \n",
       "26              3.51  \n",
       "27              3.45  \n",
       "28              3.43  \n",
       "29              3.43  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question no. 1:\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "# Retriving whole table information: \n",
    "\n",
    "wholetable=[]\n",
    "for row in driver.find_elements(By.XPATH,'(//table[@class=\"wikitable sortable jquery-tablesorter\"])[1]//tr')[1:-1]:\n",
    "    temp = ''\n",
    "    for element in row.find_elements(By.XPATH,\".//td\"):        \n",
    "        temp += element.text + '|'\n",
    "    wholetable.append(temp.split('|')[:-2])\n",
    "\n",
    "# Creating and Re-arranging in DataFrame as per Question:\n",
    "\n",
    "category = pd.DataFrame(wholetable, columns=['Rank', 'Video_Name', 'Artist_Name', 'Views_in_Billions', 'Upload_Date'])\n",
    "\n",
    "columns = ['Rank', 'Video_Name', 'Artist_Name', 'Upload_Date', 'Views_in_Billions']\n",
    "\n",
    "category.Video_Name = category.Video_Name.apply(lambda x:x[:-4].strip('\"'))\n",
    "category = category[columns]\n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14aa150a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 8 8 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASIA CUP 2023</td>\n",
       "      <td>India vs Pakistan</td>\n",
       "      <td>Pallekele International Cricket Stadium,</td>\n",
       "      <td>2 SEP 2023</td>\n",
       "      <td>10:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASIA CUP 2023</td>\n",
       "      <td>India vs Nepal</td>\n",
       "      <td>Pallekele International Cricket Stadium,</td>\n",
       "      <td>4 SEP 2023</td>\n",
       "      <td>10:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>India vs Australia</td>\n",
       "      <td>Punjab Cricket Association IS Bindra Stadium,</td>\n",
       "      <td>22 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>India vs Australia</td>\n",
       "      <td>Holkar Cricket Stadium,</td>\n",
       "      <td>24 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>India vs Australia</td>\n",
       "      <td>Saurashtra Cricket Association Stadium,</td>\n",
       "      <td>27 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>India vs Australia</td>\n",
       "      <td>MA Chidambaram Stadium,</td>\n",
       "      <td>8 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>India vs Afghanistan</td>\n",
       "      <td>Arun Jaitley Stadium,</td>\n",
       "      <td>11 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>India vs Pakistan</td>\n",
       "      <td>Narendra Modi Stadium,</td>\n",
       "      <td>14 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Match Title                Series  \\\n",
       "0                    ASIA CUP 2023     India vs Pakistan   \n",
       "1                    ASIA CUP 2023        India vs Nepal   \n",
       "2  AUSTRALIA TOUR OF INDIA 2023-24    India vs Australia   \n",
       "3  AUSTRALIA TOUR OF INDIA 2023-24    India vs Australia   \n",
       "4  AUSTRALIA TOUR OF INDIA 2023-24    India vs Australia   \n",
       "5          ICC MENS WORLD CUP 2023    India vs Australia   \n",
       "6          ICC MENS WORLD CUP 2023  India vs Afghanistan   \n",
       "7          ICC MENS WORLD CUP 2023     India vs Pakistan   \n",
       "\n",
       "                                           Place         Date          Time  \n",
       "0       Pallekele International Cricket Stadium,   2 SEP 2023  10:00 AM IST  \n",
       "1       Pallekele International Cricket Stadium,   4 SEP 2023  10:00 AM IST  \n",
       "2  Punjab Cricket Association IS Bindra Stadium,  22 SEP 2023   1:30 PM IST  \n",
       "3                        Holkar Cricket Stadium,  24 SEP 2023   1:30 PM IST  \n",
       "4        Saurashtra Cricket Association Stadium,  27 SEP 2023   1:30 PM IST  \n",
       "5                        MA Chidambaram Stadium,   8 OCT 2023   2:00 PM IST  \n",
       "6                          Arun Jaitley Stadium,  11 OCT 2023   2:00 PM IST  \n",
       "7                         Narendra Modi Stadium,  14 OCT 2023   2:00 PM IST  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question no. 2:\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "button=driver.find_element(By.XPATH,\"/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a\")\n",
    "button.click()\n",
    "time.sleep(3)\n",
    "\n",
    "try:\n",
    "    btn=driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[3]/div/div[1]\")\n",
    "    btn.click()\n",
    "    time.sleep(2)\n",
    "    btn=driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[3]/div/div[2]/div[3]\")\n",
    "    btn.click()\n",
    "    time.sleep(2)\n",
    "except ElementClickInterceptedException:\n",
    "    print('Page not loaded yet -- Please run the code again')\n",
    "    \n",
    "\n",
    "# Scraping Title from the page:\n",
    "\n",
    "title=[]\n",
    "a=driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for b in a:\n",
    "    title.append(b.text)\n",
    "\n",
    "\n",
    "# Scraping Series from the Page:\n",
    "\n",
    "series=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"match-card-middle__inner d-flex justify-content-between\"]')\n",
    "for b in a:\n",
    "    series.append(b.text.replace('\\n',' '))\n",
    "    \n",
    "\n",
    "# Scraping Place from the Page:    \n",
    "\n",
    "place=[]\n",
    "a=driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]')\n",
    "for b in a:\n",
    "    place.append(b.text)\n",
    "    \n",
    "    \n",
    "# Scraping Date from the Page: \n",
    "\n",
    "date=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "for b in a:\n",
    "    date.append(b.text)\n",
    "\n",
    "\n",
    "# Scraping Time from the Page:\n",
    "\n",
    "time=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for b in a:\n",
    "    time.append(b.text)\n",
    "\n",
    "    \n",
    "# Checking length of each column:\n",
    "\n",
    "print(len(title),len(series),len(place),len(date),len(time))\n",
    "\n",
    "Q2=pd.DataFrame({'Match Title':title,'Series':series,'Place':place,'Date':date,'Time':time})\n",
    "Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "378f8827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 66 66 66 66 66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19)- at Current prices</th>\n",
       "      <th>GSDP(19-20)- at Current prices</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP(in Billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>29</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,391</td>\n",
       "      <td>25,141</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>17,060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>24,534</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>22,488</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>24,424</td>\n",
       "      <td>20,947</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>17,797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(18-19)- at Current prices  \\\n",
       "0     1                Maharashtra                              -   \n",
       "1     2                 Tamil Nadu                      1,845,853   \n",
       "2     3              Uttar Pradesh                      1,687,818   \n",
       "3     4                    Gujarat                              -   \n",
       "4     5                  Karnataka                      1,631,977   \n",
       "..  ...                        ...                            ...   \n",
       "61   29                     Sikkim                         28,391   \n",
       "62   30                   Nagaland                              -   \n",
       "63   31          Arunachal Pradesh                              -   \n",
       "64   32                    Mizoram                         24,424   \n",
       "65   33  Andaman & Nicobar Islands                              -   \n",
       "\n",
       "   GSDP(19-20)- at Current prices Share(18-19) GDP(in Billion)  \n",
       "0                       2,632,792       13.94%         399.921  \n",
       "1                       1,630,208        8.63%         247.629  \n",
       "2                       1,584,764        8.39%         240.726  \n",
       "3                       1,502,899        7.96%         228.290  \n",
       "4                       1,493,127        7.91%         226.806  \n",
       "..                            ...          ...             ...  \n",
       "61                         25,141        0.15%          17,060  \n",
       "62                         24,534        0.15%               -  \n",
       "63                         22,488        0.13%               -  \n",
       "64                         20,947        0.13%          17,797  \n",
       "65                              -            -               -  \n",
       "\n",
       "[66 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question no. 3:\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.statisticstimes.com/economy/india-statistics.php\")\n",
    "\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "button=driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "# Scraping Rank from the page:\n",
    "\n",
    "rank=[]\n",
    "a=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[1]')\n",
    "try:\n",
    "    for b in a:\n",
    "        rank.append(b.text)\n",
    "except NoSuchElementException:\n",
    "    print('-')\n",
    "\n",
    "\n",
    "# Scraping State from Page:\n",
    "\n",
    "state=[]\n",
    "a=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[2]')\n",
    "try:\n",
    "    for b in a:\n",
    "        state.append(b.text)\n",
    "except NoSuchElementException:\n",
    "    print('-')\n",
    "\n",
    "\n",
    "# Scraping GSDP(18-19) at Current Prices from Page:\n",
    "\n",
    "gsdp1=[]\n",
    "a=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[3]')\n",
    "try:\n",
    "    for b in a:\n",
    "        gsdp1.append(b.text)\n",
    "except NoSuchElementException:\n",
    "    print('-')\n",
    "\n",
    "\n",
    "# Scraping GSDP(19-20) at Current Prices from Page:\n",
    "\n",
    "gsdp2=[]\n",
    "a=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[4]')\n",
    "try:\n",
    "    for b in a:\n",
    "        gsdp2.append(b.text)\n",
    "except NoSuchElementException:\n",
    "    print('-')\n",
    "\n",
    "\n",
    "# Scraping Share (18-19) at Current Prices from Page:\n",
    "\n",
    "share=[]\n",
    "a=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[5]')\n",
    "try:\n",
    "    for b in a:\n",
    "        share.append(b.text)\n",
    "except NoSuchElementException:\n",
    "    print('-')\n",
    "\n",
    "\n",
    "# Scraping GDP from the page:\n",
    "\n",
    "gdp=[]\n",
    "a=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[6]')\n",
    "try:\n",
    "    for b in a:\n",
    "        gdp.append(b.text)\n",
    "except NoSuchElementException:\n",
    "    print('-')\n",
    "\n",
    "\n",
    "# Checking lenght of each column:\n",
    "\n",
    "print(len(rank),len(state),len(gsdp1),len(gsdp2),len(share),len(gdp))\n",
    "\n",
    "Q3=pd.DataFrame({'Rank':rank,'State':state,'GSDP(18-19)- at Current prices':gsdp1,'GSDP(19-20)- at Current prices':gsdp2,'Share(18-19)':share,'GDP(in Billion)':gdp})\n",
    "Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30fc4578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repositary Title</th>\n",
       "      <th>Repositary description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Languages Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joonspk-research / generative_agents</td>\n",
       "      <td>Generative Agents: Interactive Simulacra of Hu...</td>\n",
       "      <td>819</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>modelscope / facechain</td>\n",
       "      <td>FaceChain is a deep-learning toolchain for gen...</td>\n",
       "      <td>67</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phoboslab / wipeout-rewrite</td>\n",
       "      <td>Multiplayer at the speed of light</td>\n",
       "      <td>36</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clockworklabs / SpacetimeDB</td>\n",
       "      <td>A youtube-dl fork with additional features and...</td>\n",
       "      <td>50</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yt-dlp / yt-dlp</td>\n",
       "      <td>Minimalist ML framework for Rust</td>\n",
       "      <td>4,395</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id-Software / quake2-rerelease-dll</td>\n",
       "      <td>All Algorithms implemented in Python</td>\n",
       "      <td>98</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>huggingface / candle</td>\n",
       "      <td>Bitcoin Core integration/staging tree</td>\n",
       "      <td>193</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TheAlgorithms / Python</td>\n",
       "      <td>This repo is a pipeline of VITS finetuning for...</td>\n",
       "      <td>41,184</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bitcoin / bitcoin</td>\n",
       "      <td>Original reference implementation of \"3D Gauss...</td>\n",
       "      <td>35,522</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Plachtaa / VITS-fast-fine-tuning</td>\n",
       "      <td>Drag &amp; drop UI to build your customized LLM flow</td>\n",
       "      <td>415</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>graphdeco-inria / gaussian-splatting</td>\n",
       "      <td>The Patterns of Scalable, Reliable, and Perfor...</td>\n",
       "      <td>83</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FlowiseAI / Flowise</td>\n",
       "      <td>面向网络安全从业者的知识文库🍃</td>\n",
       "      <td>5,393</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>binhnguyennus / awesome-scalability</td>\n",
       "      <td>A decentralized, Ethereum-equivalent ZK-Rollup. 🥁</td>\n",
       "      <td>5,158</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PeiQi0 / PeiQi-WIKI-Book</td>\n",
       "      <td>分享 GitHub 上有趣、入门级的开源项目。Share interesting, entr...</td>\n",
       "      <td>447</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DeBankDeFi / DeBankChain</td>\n",
       "      <td>🥷 Superagent - Build, deploy, and manage LLM-p...</td>\n",
       "      <td>34</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>taikoxyz / taiko-mono</td>\n",
       "      <td>Fork of Paper which adds regionised multithrea...</td>\n",
       "      <td>800</td>\n",
       "      <td>Kotlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>521xueweihan / HelloGitHub</td>\n",
       "      <td>Command-line program to download videos from Y...</td>\n",
       "      <td>9,150</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>homanp / superagent</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>356</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PaperMC / Folia</td>\n",
       "      <td>Simple Directmedia Layer</td>\n",
       "      <td>237</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ytdl-org / youtube-dl</td>\n",
       "      <td>♾ Infisical is an open-source, end-to-end encr...</td>\n",
       "      <td>9,231</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Repositary Title  \\\n",
       "0   joonspk-research / generative_agents   \n",
       "1                 modelscope / facechain   \n",
       "2            phoboslab / wipeout-rewrite   \n",
       "3            clockworklabs / SpacetimeDB   \n",
       "4                        yt-dlp / yt-dlp   \n",
       "5     id-Software / quake2-rerelease-dll   \n",
       "6                   huggingface / candle   \n",
       "7                 TheAlgorithms / Python   \n",
       "8                      bitcoin / bitcoin   \n",
       "9       Plachtaa / VITS-fast-fine-tuning   \n",
       "10  graphdeco-inria / gaussian-splatting   \n",
       "11                   FlowiseAI / Flowise   \n",
       "12   binhnguyennus / awesome-scalability   \n",
       "13              PeiQi0 / PeiQi-WIKI-Book   \n",
       "14              DeBankDeFi / DeBankChain   \n",
       "15                 taikoxyz / taiko-mono   \n",
       "16            521xueweihan / HelloGitHub   \n",
       "17                   homanp / superagent   \n",
       "18                       PaperMC / Folia   \n",
       "19                 ytdl-org / youtube-dl   \n",
       "\n",
       "                               Repositary description Contributors Count  \\\n",
       "0   Generative Agents: Interactive Simulacra of Hu...                819   \n",
       "1   FaceChain is a deep-learning toolchain for gen...                 67   \n",
       "2                   Multiplayer at the speed of light                 36   \n",
       "3   A youtube-dl fork with additional features and...                 50   \n",
       "4                    Minimalist ML framework for Rust              4,395   \n",
       "5                All Algorithms implemented in Python                 98   \n",
       "6               Bitcoin Core integration/staging tree                193   \n",
       "7   This repo is a pipeline of VITS finetuning for...             41,184   \n",
       "8   Original reference implementation of \"3D Gauss...             35,522   \n",
       "9    Drag & drop UI to build your customized LLM flow                415   \n",
       "10  The Patterns of Scalable, Reliable, and Perfor...                 83   \n",
       "11                                    面向网络安全从业者的知识文库🍃              5,393   \n",
       "12  A decentralized, Ethereum-equivalent ZK-Rollup. 🥁              5,158   \n",
       "13  分享 GitHub 上有趣、入门级的开源项目。Share interesting, entr...                447   \n",
       "14  🥷 Superagent - Build, deploy, and manage LLM-p...                 34   \n",
       "15  Fork of Paper which adds regionised multithrea...                800   \n",
       "16  Command-line program to download videos from Y...              9,150   \n",
       "17                                   Jupyter Notebook                356   \n",
       "18                           Simple Directmedia Layer                237   \n",
       "19  ♾ Infisical is an open-source, end-to-end encr...              9,231   \n",
       "\n",
       "      Languages Used  \n",
       "0             Python  \n",
       "1                  C  \n",
       "2               Rust  \n",
       "3             Python  \n",
       "4                  C  \n",
       "5               Rust  \n",
       "6             Python  \n",
       "7                C++  \n",
       "8             Python  \n",
       "9             Python  \n",
       "10        TypeScript  \n",
       "11                Go  \n",
       "12              HTML  \n",
       "13            Python  \n",
       "14        JavaScript  \n",
       "15            Kotlin  \n",
       "16            Python  \n",
       "17  Jupyter Notebook  \n",
       "18                 C  \n",
       "19        TypeScript  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question no. 4:\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://github.com/topics\")\n",
    "\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "button=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/main/div[1]/nav/div/a[3]\")\n",
    "button.click()\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "# Scraping Repositary title from the page:\n",
    "\n",
    "name=[]\n",
    "a=driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]')\n",
    "for b in a:\n",
    "    name.append(b.text)\n",
    "name=name[:20]\n",
    "\n",
    "\n",
    "# Scraping Repositary description from the page:\n",
    "\n",
    "desc=[]\n",
    "a=driver.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "try:\n",
    "    for b in a:\n",
    "        desc.append(b.text)\n",
    "except NoSuchElementException:\n",
    "    print('-')\n",
    "desc=desc[:20]\n",
    "\n",
    "\n",
    "# Scraping Language from the page:\n",
    "\n",
    "lang=[]\n",
    "a=driver.find_elements(By.XPATH,'//span[@class=\"d-inline-block ml-0 mr-3\"]/span[2]')\n",
    "try:\n",
    "    for b in a:\n",
    "        lang.append(b.text)\n",
    "except NoSuchElementException:\n",
    "    print('-')\n",
    "lang=lang[:20]\n",
    "\n",
    "\n",
    "# Scraping Contributors count from the page:\n",
    "\n",
    "contri=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"f6 color-fg-muted mt-2\"]/a[2]')\n",
    "try:\n",
    "    for b in a:\n",
    "        contri.append(b.text)\n",
    "except NoSuchElementException:\n",
    "    print('-')\n",
    "contri=contri[:20]\n",
    "\n",
    "# Checking length of each column:\n",
    "\n",
    "print(len(name),len(desc),len(lang),len(contri))\n",
    "\n",
    "Q4 = pd.DataFrame({'Repositary Title':name,'Repositary description':desc,'Contributors Count': contri,'Languages Used': lang})\n",
    "Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9703d0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meltdown</td>\n",
       "      <td>Travis Scott Featuring Drake</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FE!N</td>\n",
       "      <td>Travis Scott Featuring Playboi Carti</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Oh U Went</td>\n",
       "      <td>Young Thug Featuring Drake</td>\n",
       "      <td>66</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ICU</td>\n",
       "      <td>Coco Jones</td>\n",
       "      <td>71</td>\n",
       "      <td>62</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Pound Town 2</td>\n",
       "      <td>Sexyy Red &amp; Tay Keith &amp; Nicki Minaj</td>\n",
       "      <td>74</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Bzrp Music Sessions, Vol. 55</td>\n",
       "      <td>Bizarrap &amp; Peso Pluma</td>\n",
       "      <td>72</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Johnny Dang</td>\n",
       "      <td>That Mexican OT, Paul Wall &amp; DRODi</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Song Name                           Artist Name  \\\n",
       "0                     Last Night                         Morgan Wallen   \n",
       "1                       Fast Car                            Luke Combs   \n",
       "2                       Meltdown          Travis Scott Featuring Drake   \n",
       "3                   Cruel Summer                          Taylor Swift   \n",
       "4                           FE!N  Travis Scott Featuring Playboi Carti   \n",
       "..                           ...                                   ...   \n",
       "95                     Oh U Went            Young Thug Featuring Drake   \n",
       "96                           ICU                            Coco Jones   \n",
       "97                  Pound Town 2   Sexyy Red & Tay Keith & Nicki Minaj   \n",
       "98  Bzrp Music Sessions, Vol. 55                 Bizarrap & Peso Pluma   \n",
       "99                   Johnny Dang    That Mexican OT, Paul Wall & DRODi   \n",
       "\n",
       "   Last Week Rank Peak Rank Weeks on Board  \n",
       "0               2         1             27  \n",
       "1               3         2             19  \n",
       "2               -         3              1  \n",
       "3               6         4             13  \n",
       "4               -         5              1  \n",
       "..            ...       ...            ...  \n",
       "95             66        19              6  \n",
       "96             71        62             18  \n",
       "97             74        66              9  \n",
       "98             72        31              9  \n",
       "99             96        96              3  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question no. 5:\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.billboard.com/charts/\")\n",
    "\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "button=driver.find_element(By.XPATH,\"/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[3]/a\")\n",
    "button.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# Scraping Song title from the page:\n",
    "\n",
    "song=[]\n",
    "a=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li/h3')\n",
    "try:\n",
    "    for b in a:\n",
    "        song.append(b.text)\n",
    "except NoSuchElementException:\n",
    "    print('-')\n",
    "\n",
    "remaining=[]\n",
    "a=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li/span[1]')\n",
    "try:\n",
    "    for b in a:\n",
    "        remaining.append(b.text)\n",
    "except NoSuchElementException:\n",
    "    print('-') \n",
    "    \n",
    "    \n",
    "# Scraping Artist name from the page:\n",
    "\n",
    "artist=remaining[0::4]\n",
    "\n",
    "\n",
    "# Scraping last week rank name from the page:\n",
    "\n",
    "lrank=remaining[1::4]\n",
    "\n",
    "# Scraping Peak rank from the page:\n",
    "\n",
    "prank=remaining[2::4]\n",
    "\n",
    "# Scraping Weeks on Chart from the page:\n",
    "\n",
    "week=remaining[3::4]\n",
    "\n",
    "# Checking lengths of each column:\n",
    "print(len(song),len(artist),len(lrank),len(prank),len(week))\n",
    "\n",
    "Q5 = pd.DataFrame({'Song Name':song,'Artist Name':artist,'Last Week Rank':lrank,'Peak Rank':prank,'Weeks on Board':week})\n",
    "Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c953651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question no. 6:\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare \")\n",
    "\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "# Scraping Book Name from the page:\n",
    "book=[]\n",
    "a=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "for b in a:\n",
    "    book.append(b.text)\n",
    "\n",
    "    \n",
    "# Scraping Author Name from the page\n",
    "author=[]\n",
    "a=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "for b in a:\n",
    "    author.append(b.text)\n",
    "\n",
    "\n",
    "# Scraping Volumes Sold from the page:\n",
    "volume=[]\n",
    "a=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "for b in a:\n",
    "    volume.append(b.text)\n",
    "\n",
    "\n",
    "# Scraping Publisher Sold from the page:\n",
    "publisher=[]\n",
    "a=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "for b in a:\n",
    "    publisher.append(b.text)\n",
    "\n",
    "\n",
    "# Scraping Genre Sold from the page:\n",
    "gen=[]\n",
    "a=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "for b in a:\n",
    "    gen.append(b.text)\n",
    "\n",
    "    \n",
    "# Checking length of each column:\n",
    "print(len(book),len(author),len(volume),len(publisher),len(gen))\n",
    "\n",
    "Q6=pd.DataFrame({'Book Name':book,'Author Name':author,'Volumes Sold':volume,'Publisher':publisher,'Genre':gen})\n",
    "Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08e001db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,192,163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,266,063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,040,592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>305,851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>264,924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>52,407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>64,432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>210,005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>43,661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>263,471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,192,163  \n",
       "1    51 min     8.7  1,266,063  \n",
       "2    44 min     8.1  1,040,592  \n",
       "3    60 min     7.5    305,851  \n",
       "4    43 min     7.6    264,924  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     52,407  \n",
       "96   50 min     7.8     64,432  \n",
       "97   42 min     8.1    210,005  \n",
       "98   45 min       7     43,661  \n",
       "99  572 min     8.6    263,471  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question no. 7:\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n",
    "\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "# Scraping Name from the page:\n",
    "name=[]\n",
    "a=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/a')\n",
    "for b in a:\n",
    "    name.append(b.text)\n",
    "\n",
    "# Scraping Year Span from the page:    \n",
    "span=[]\n",
    "a=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/span[2]')\n",
    "for b in a:\n",
    "    span.append(b.text)\n",
    "\n",
    "\n",
    "# Scraping Genre from the page:\n",
    "gen=[]\n",
    "a=driver.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"]/span[5]')\n",
    "for b in a:\n",
    "    gen.append(b.text)\n",
    "\n",
    "\n",
    "# Scraping Run Time from the page:\n",
    "time=[]\n",
    "a=driver.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"]/span[3]')\n",
    "for b in a:\n",
    "    time.append(b.text)\n",
    "\n",
    "\n",
    "# Scraping Ratings from the page:\n",
    "rating=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-star small\"]/span[2]')\n",
    "for b in a:\n",
    "    rating.append(b.text)\n",
    "\n",
    "\n",
    "# Scraping Run Time from the page:\n",
    "run=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/p[4]/span[2]')\n",
    "for b in a:\n",
    "    run.append(b.text)\n",
    "\n",
    "    \n",
    "# Checking length of each column:\n",
    "print(len(name),len(span),len(time),len(gen),len(rating),len(run))\n",
    "\n",
    "Q7=pd.DataFrame({'Name':name,'Year Span':span,'Genre':gen,'Run Time':time,'Ratings':rating,'Votes':run})\n",
    "Q7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca0e55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataSet Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No. of Instances</th>\n",
       "      <th>No. of Attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Attributes</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Attributes</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Attributes</td>\n",
       "      <td>5/1/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>16 Attributes</td>\n",
       "      <td>9/14/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td></td>\n",
       "      <td>20 Attributes</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Attributes</td>\n",
       "      <td>7/1/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Attributes</td>\n",
       "      <td>11/1/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3.81K Instances</td>\n",
       "      <td>8 Attributes</td>\n",
       "      <td>10/6/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1.73K Instances</td>\n",
       "      <td>6 Attributes</td>\n",
       "      <td>6/1/1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>8.12K Instances</td>\n",
       "      <td>22 Attributes</td>\n",
       "      <td>4/27/1987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           DataSet Name     Data Type            Task  \\\n",
       "0                                  Iris  Multivariate  Classification   \n",
       "1                         Heart Disease  Multivariate  Classification   \n",
       "2                                 Adult  Multivariate  Classification   \n",
       "3                      Dry Bean Dataset  Multivariate  Classification   \n",
       "4                              Diabetes                                 \n",
       "5                                  Wine  Multivariate  Classification   \n",
       "6  Breast Cancer Wisconsin (Diagnostic)  Multivariate  Classification   \n",
       "7            Rice (Cammeo and Osmancik)  Multivariate  Classification   \n",
       "8                        Car Evaluation  Multivariate  Classification   \n",
       "9                              Mushroom  Multivariate  Classification   \n",
       "\n",
       "               Attribute Type  No. of Instances No. of Attribute       Year  \n",
       "0                        Real     150 Instances     4 Attributes   7/1/1988  \n",
       "1  Categorical, Integer, Real     303 Instances    13 Attributes   7/1/1988  \n",
       "2        Categorical, Integer  48.84K Instances    14 Attributes   5/1/1996  \n",
       "3               Integer, Real  13.61K Instances    16 Attributes  9/14/2020  \n",
       "4        Categorical, Integer                      20 Attributes        N/A  \n",
       "5               Integer, Real     178 Instances    13 Attributes   7/1/1991  \n",
       "6                        Real     569 Instances    30 Attributes  11/1/1995  \n",
       "7                        Real   3.81K Instances     8 Attributes  10/6/2019  \n",
       "8                 Categorical   1.73K Instances     6 Attributes   6/1/1997  \n",
       "9                 Categorical   8.12K Instances    22 Attributes  4/27/1987  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question no. 8:\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://archive.ics.uci.edu/\")\n",
    "\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "button=driver.find_element(By.XPATH,'//a[@class=\"btn-primary btn\"]')\n",
    "button.click()\n",
    "time.sleep(3)\n",
    "\n",
    "button=driver.find_element(By.XPATH,'//span[@class=\"swap-on text-primary-content\"]')\n",
    "button.click()\n",
    "time.sleep(3)\n",
    "\n",
    "# Scraping Dataset Name from the page:\n",
    "name=[]\n",
    "a=driver.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "for b in a:\n",
    "    name.append(b.text)\n",
    "\n",
    "\n",
    "# Scraping Data type from the page:\n",
    "types=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[2]/span')\n",
    "for b in a:\n",
    "    types.append(b.text)\n",
    "\n",
    "\n",
    "# Scraping Task from the page:\n",
    "task=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[1]/span')\n",
    "for b in a:\n",
    "    task.append(b.text)\n",
    "\n",
    "\n",
    "# Scraping Attribute Type from the page:\n",
    "atype=[]\n",
    "a=driver.find_elements(By.XPATH,'//tbody[@class=\"border\"]/tr/td[2]')\n",
    "for b in a:\n",
    "    atype.append(b.text)\n",
    "\n",
    "\n",
    "# Scraping No. of Instances from the page:\n",
    "instance=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[3]/span')\n",
    "for b in a:\n",
    "    instance.append(b.text)\n",
    "    \n",
    "\n",
    "# Scraping No. of Attributes from the page:\n",
    "attributes=[]\n",
    "a=driver.find_elements(By.XPATH,'//div[@class=\"my-2 hidden gap-4 md:grid grid-cols-12\"]/div[4]/span')\n",
    "for b in a:\n",
    "    attributes.append(b.text)\n",
    "    \n",
    "\n",
    "# Scraping Year from the page:\n",
    "year=[]\n",
    "a=driver.find_elements(By.XPATH,'//tbody[@class=\"border\"]/tr/td[3]')\n",
    "for b in a:\n",
    "    year.append(b.text)\n",
    "\n",
    "\n",
    "# Checking length of each  column:\n",
    "print(len(name),len(types),len(task),len(atype),len(instance),len(attributes),len(year))\n",
    "\n",
    "Q8=pd.DataFrame({'DataSet Name':name,'Data Type':types,'Task':task,'Attribute Type':atype,'No. of Instances':instance,'No. of Attribute':attributes,'Year':year})\n",
    "Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e873f24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
